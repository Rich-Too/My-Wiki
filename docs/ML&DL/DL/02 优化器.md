# What do if network fails to train

## General Guidance

![image-20230311142638085](static/image-20230311142638085.png)

å¯ä»¥å…ˆè·‘ä¸€äº›æ¯”è¾ƒå°çš„ã€æ¯”è¾ƒæµ…çš„ç½‘ç»œï¼Œæˆ–ç”šè‡³ç”¨ä¸€äº›éæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œæ¯”å¦‚çº¿æ€§æ¨¡å‹ã€SVMï¼Œï¼ˆSVMç›¸æ¯”è¾ƒä¸‹ä¸ä¼šæœ‰ä¼˜åŒ–å¤±è´¥çš„é—®é¢˜ï¼‰åœ¨å®ƒä»¬çš„èƒ½åŠ›èŒƒå›´ä¹‹å†…,æ‰¾å‡ºä¸€ç»„æœ€å¥½çš„å‚æ•°ï¼Œè§‚å¯Ÿå¯ä»¥å¾—åˆ°ä»€ä¹ˆæ ·çš„æŸå¤±ã€‚æ¥ä¸‹æ¥å†ä½¿ç”¨æ·±ä¸€äº›çš„æ¨¡å‹ï¼Œå¦‚æœæ¯”è¾ƒèµ·æ¥ï¼Œæ·±çš„æ¨¡å‹æ˜æ˜çµæ´»æ€§æ¯”è¾ƒå¤§ï¼Œä½†æŸå¤±å´æ¯”æµ…çš„æ¨¡å‹æ›´ä½ï¼Œè¯´æ˜ä¼˜åŒ–æœ‰é—®é¢˜ã€‚ 



**Overfitting** 

Small loss on training data, large loss on testing data. 

- More training data
- Data augmentation
    - å¦‚å›¾ç‰‡è¿›è¡Œå·¦å³ç¿»è½¬

- Constrain
    - Less parameters, sharing parameters
    - Less features
    - Early stopping
    - Regularization
    - Dropout

**Cross Validation**

Split training set to traing set and validation set. 

![image-20230311143933951](static/image-20230311143933951.png)

**Mismatch**

Your training and testing data have different distributions. Simply increasing the training data will not help.

## Optimization Strategy

### Small-gradient

![image-20230311144937418](static/image-20230311144937418.png)

local minima å’Œ saddle point éƒ½ä¼šå‡ºç° 0ï¼Œå¦‚ä½•åˆ¤æ–­ï¼Ÿ

$L(\theta)$ around $\theta = {\theta}^{\prime}$ can be **approximated** below: 

$L(\boldsymbol{\theta}) \approx L\left(\boldsymbol{\theta}^{\prime}\right)+\left(\boldsymbol{\theta}-\boldsymbol{\theta}^{\prime}\right)^{T} g+\frac{1}{2}\left(\boldsymbol{\theta}-\boldsymbol{\theta}^{\prime}\right)^{T} H\left(\boldsymbol{\theta}-\boldsymbol{\theta}^{\prime}\right)$

![image-20230311151322604](static/image-20230311151322604.png)

- Gradient $g$ is a vector:

$g=\nabla L\left(\boldsymbol{\theta}^{\prime}\right) \quad g_{i}=\frac{\partial L\left(\boldsymbol{\theta}^{\prime}\right)}{\partial \boldsymbol{\theta}_{i}}$

- Hessian ğ» is a matrix:
  $$H_{ij}=\dfrac{\partial^2}{\partial\theta_i\partial\theta_j}L(\theta')$$

**At critical point**, $\left(\boldsymbol{\theta}-\boldsymbol{\theta}^{\prime}\right)^{T} g = 0$ :

![image-20230311151538392](static/image-20230311151538392.png)

- To deal with saddle point:

![image-20230311151911645](static/image-20230311151911645.png)

> ä½†å®é™…ä¸Š,æˆ‘ä»¬å‡ ä¹ä¸ä¼šçœŸçš„æŠŠæµ·æ£®çŸ©é˜µç®—å‡ºæ¥ï¼Œå› ä¸ºæµ·æ£®çŸ©é˜µéœ€è¦ç®—äºŒæ¬¡å¾®åˆ†ï¼Œè®¡ç®—è¿™ä¸ªçŸ©é˜µçš„è¿ç®—é‡éå¸¸å¤§ï¼Œä½•å†µæˆ‘ä»¬è¿˜è¦æŠŠå®ƒçš„ç‰¹å¾å€¼è·Ÿç‰¹å¾å‘é‡æ‰¾å‡ºæ¥ã€‚

### Batch

![image-20230311155341606](static/image-20230311155341606.png)

![image-20230311160159245](static/image-20230311160159245.png)

Batch size is a hyperparameter we have to decide.

- Larger batch size does not require longer time to compute gradient (unless batch size is too large)
- Smaller batch requires longer time for one epoch (longer time for seeing all data once)
- Smaller batch size has better performance, "Noisy" update is better for training

### Momentum

è€ƒè™‘ç‰©ç†ä¸–ç•Œçš„å°çƒä»é«˜å¤„æ»šä¸‹ï¼Œå› ä¸ºæœ‰å‰é¢çš„ç§¯ç´¯é€Ÿåº¦ï¼Œå°çƒå¹¶ä¸ä¼šå¡åœ¨éç‚¹å¤„ã€‚

$\theta^{i+1} = \theta^{i}-\eta g^{i}$

![image-20230311160649820](static/image-20230311160649820.png)

### Learing Rate Adjustment

> äº‹å®ä¸Šï¼Œcritical point å¾€å¾€ä¸æ˜¯è®­ç»ƒå¡ä½çš„åŸå› ã€‚å¯¹äºä¸€èˆ¬çš„æ¢¯åº¦ä¸‹é™è®­ç»ƒï¼Œå¾€å¾€æ¢¯åº¦è¿˜å¾ˆå¤§ï¼ŒæŸå¤±å°±å·²ç»é™äº†ä¸‹å»ï¼Œè®­ç»ƒåœ¨è¿˜æ²¡æœ‰èµ°åˆ°ä¸´ç•Œç‚¹çš„æ—¶å€™å°±å·²ç»åœæ­¢äº†ã€‚å¯¹äºæŸä¸€ä¸ªæ–¹å‘ï¼Œå¦‚æœæ¢¯åº¦çš„å€¼å¾ˆå°ï¼Œæˆ‘ä»¬ä¼šå¸Œæœ›å­¦ä¹ ç‡è°ƒå¤§ä¸€ç‚¹ï¼›è€Œå¦‚æœæŸä¸€ä¸ªæ–¹å‘ä¸Šéå¸¸é™¡å³­ï¼Œå¡åº¦å¾ˆå¤§ï¼Œæˆ‘ä»¬ä¼šå¸Œæœ›å­¦ä¹ ç‡å¯ä»¥å°ä¸€ç‚¹ã€‚ä¸åŒçš„å‚æ•°éœ€è¦è¢«è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡ã€‚

Loss keep stable does not mean small gradient. Different parameters needs different learning rate.

#### Root Mean Square

Used in Adarad.

![image-20230311161501695](static/image-20230311161501695.png)



#### RMSProp

å¯ä»¥è°ƒæ•´è¿‡å»çš„ $\sigma$ çš„é‡è¦æ€§ã€‚

![image-20230311161617139](static/image-20230311161617139.png)



#### **Adam**: RMSProp + Momentum

pytorch æœ‰å®Œå¤‡çš„å¥—ä»¶ï¼Œé»˜è®¤å‚æ•°æ•ˆæœå°±å·²ç»å¾ˆå¥½ã€‚

#### Learning Rate Scheduling

If learning date $\eta$ keeps invariant, picture will be left below. 

![image-20230311162918674](static/image-20230311162918674.png)

åœ¨ BC æ®µï¼Œçºµè½´çš„æ–¹å‘æ¢¯åº¦å¾ˆå°ï¼Œå› æ­¤çºµè½´æ–¹å‘ç´¯ç§¯äº†å¾ˆå°çš„ $Ïƒ_t$ ï¼Œè€Œç´¯ç§¯åˆ°ä¸€å®šç¨‹åº¦ä»¥åï¼Œæ­¥ä¼å°±ä¼šå˜å¾—å¾ˆå¤§ã€‚

So let $\eta$ be a variable of $t$.

$\theta_i^{t+1}\leftarrow\theta_i^t-\dfrac{\eta^t}{\sigma_i^t}g_i^t$

![image-20230311163249276](static/image-20230311163249276.png)

![image-20231115214518052](static/image-20231115214518052.png)

> é™¤äº†æ®‹å·®ç½‘ç»œï¼ŒBERT å’Œ Transformer çš„è®­ç»ƒä¹Ÿéƒ½ä½¿ç”¨äº†é¢„çƒ­æ³•ã€‚

### Loss Function

Consider classification as regression, think each class as one-hot vector. 

$\hat{y}=\begin{bmatrix}1\\ 0\\ 0\end{bmatrix}\text{or}\begin{bmatrix}0\\ 1\\ 0\end{bmatrix}\text{or}\begin{bmatrix}0\\ 0\\ 1\end{bmatrix}$

![image-20230311164804504](static/image-20230311164804504.png)

**softmax:** $y_i'=\frac{exp(y_i)}{\sum_jexp(y_i)}$

Loss of Classification:

- Mean Square Error (MSE): $e=\sum(\hat y_i-y'_i)^2$

- Cross-entropy: $e=-\sum\hat y_i\ln y'_i$  æ•ˆæœæœ€å¥½ 

**Minimizing cross-entropy** is equivalent to **maximizing likelihood**. Changing the loss function can change the difficulty of optimization.

è§ä¸‹å›¾æ‰€ç¤ºï¼Œå‡è®¾ $y_3$ å›ºå®šï¼Œé€‰å– MSE æ–¹æ³•æ—¶ï¼Œè®­ç»ƒä¼šè¢«å¡ä½ï¼Œè€Œ cross-entropy ä¼šæœ‰æ–œå¡å¯ä»¥å‰è¿›ã€‚

![image-20231116154257910](static/image-20231116154257910.png)













## æœºå™¨å­¦ä¹ åŸç†æµ…è°ˆ

> å¯»æ‰¾åˆé€‚çš„å‚æ•°$h$å¯¹æ•°ç å®è´å’Œå®å¯æ¢¦è¿›è¡Œåˆ†ç±»ã€‚

$h^{all}=arg\underset{h}{\text{min}}L(h,D_{all})$
$h^{train}=arg\underset{h}{\text{train}}L(h,D_{all})$

we hope $L(h^{train},D_{all})$ and $L(h^{all},D_{D_{all}})$ are close.

![image-20230405114533551](static/image-20230405114533551.png)

So the key question is the choice of $D_{train}$.

![image-20230405114839090](static/image-20230405114839090.png)

