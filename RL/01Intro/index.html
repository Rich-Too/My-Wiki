
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://rich-too.github.io/My-Wiki/RL/01Intro/">
      
      
      
      <link rel="icon" href="../../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.19">
    
    
      
        <title>Reinforcement Learning - RichToo的垃圾堆</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
    
    
      <link rel="stylesheet" href="../../assets/css/extra.css">
    
      <link rel="stylesheet" href="../../assets/css/font.css">
    
      <link rel="stylesheet" href="../../assets/css/heiti.css">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Sans&family=PT+Sans&display=swap">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=Open+Sans">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=JetBrains+Mono">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto+Mono">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Source+Sans+Pro&display=swap">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lxgw-wenkai-screen-webfont/1.7.0/style.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hack-font@3/build/web/hack.css">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=Fira+Sans">
    
      <link rel="stylesheet" href="https://fonts.loli.net/css?family=PT+Sans">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reinforcement-learning" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="RichToo的垃圾堆" class="md-header__button md-logo" aria-label="RichToo的垃圾堆" data-md-component="logo">
      
  <img src="../../assets/favicon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            RichToo的垃圾堆
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reinforcement Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="default" data-md-color-accent="default"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/Rich-Too/My-Wiki" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    My-Wiki
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        主页
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Toolkit/" class="md-tabs__link">
        开发工具
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../DL/Tools/Math.md" class="md-tabs__link">
        深度学习
      </a>
    </li>
  

  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="RichToo的垃圾堆" class="md-nav__button md-logo" aria-label="RichToo的垃圾堆" data-md-component="logo">
      
  <img src="../../assets/favicon.png" alt="logo">

    </a>
    RichToo的垃圾堆
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Rich-Too/My-Wiki" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    My-Wiki
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../..">主页</a>
          
            <label for="__nav_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          主页
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../me.md" class="md-nav__link">
        关于我
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../Toolkit/">开发工具</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          开发工具
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../Toolkit/git/">Git</a>
          
            <label for="__nav_2_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Git
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/git/01.Git%E8%B5%B7%E6%AD%A5/" class="md-nav__link">
        Git起步
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/git/02.Git%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        Git基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/git/03.%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E4%B8%8E%E5%88%86%E6%94%AF/" class="md-nav__link">
        Git远程仓库与分支
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/git/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" class="md-nav__link">
        Git常用命令
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/vim/vim/" class="md-nav__link">
        Vim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Toolkit/shell/Shell%20Tools%20and%20Scripting/" class="md-nav__link">
        Shell
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
          Tools
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Tools
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DL/Tools/Math.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DL/Tools/NumPy.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DL/Tools/OS.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DL/Tools/Pandas.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DL/Tools/python.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#terminology" class="md-nav__link">
    Terminology:
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#--using-the-reward-function-to-find-the-optimal-actor" class="md-nav__link">
    - Using the reward function to find the optimal actor
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="reinforcement-learning">Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permanent link">&para;</a></h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8V2m6.78 1a.69.69 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38-2.5-2.5Z"/></svg></span> 约 1466 个字 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3L12.5 13Z"/></svg></span> 预计阅读时间 5 分钟</p>
</div>
<blockquote>
<p>强化学习的目标是研究从马尔科夫决策过程出发，放松各种限制。</p>
<p><span class="arithmatex">\(s_t\)</span> 可能是数量庞大或者无限的，或者是连续而非离散的，或者是只能部分被观察或者不能被观察。在此情况下，强化学习的目标不是寻找最优解，而是寻找次优解。</p>
</blockquote>
<p><a class="glightbox" href=".static/Figure_chapterRelationship.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="Figure_chapterRelationship.png" src=".static/Figure_chapterRelationship.png" /></a></p>
<h2 id="terminology"><strong>Terminology:</strong><a class="headerlink" href="#terminology" title="Permanent link">&para;</a></h2>
<ul>
<li>Agent</li>
<li>policy function: <span class="arithmatex">\(\pi(s,a) -&gt; [0,1]\)</span></li>
<li><span class="arithmatex">\(\pi(a|s)=p(A=a|S=s)\)</span></li>
<li>Output the vector including probabilities for all the actions.</li>
<li>reward: <span class="arithmatex">\(R,r\)</span></li>
<li>state transition: random  randomness from environment</li>
<li><span class="arithmatex">\(p(s'|s,a)=P(S'=s'|,A=a)\)</span></li>
<li>Randomness</li>
<li>action</li>
<li>state transition </li>
<li>Return</li>
<li>Cumulative future reward</li>
<li><span class="arithmatex">\(U_t=R_t+R_{t+1}+R_{t+2}+R_{t+3}+\cdots+R_n.\)</span></li>
<li>Discounted return (at time <span class="arithmatex">\(t\)</span>)</li>
<li>Future reward is less valuable than present reward.</li>
<li><span class="arithmatex">\(R_{t+1}\)</span> should be given less weight than <span class="arithmatex">\(R_t\)</span>.</li>
<li>$U_t=R_t+\gamma\cdot R_{t+1}+\gamma^2\cdot R_{t+2}+\gamma^3\cdot R_{t+3}+\cdots $</li>
<li>Episode</li>
<li>
<p>An episode is usually assumed to be a finite trajectory. </p>
</li>
<li>
<p>Value Function for MRP</p>
</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
V(s)&amp; =\mathbb{E}[U_t|S_t=s]  \\
&amp;=\mathbb{E}[R_t+\gamma R_{t+1}+\gamma^2R_{t+2}+\ldots|S_t=s] \\
&amp;=\mathbb{E}[R_t+\gamma(R_{t+1}+\gamma R_{t+2}+\ldots)|S_t=s] \\
&amp;=\mathbb{E}[R_t+\gamma G_{t+1}|S_t=s] \\
&amp;=\mathbb{E}[R_t+\gamma V(S_{t+1})|S_t=s]\\
&amp;=r(s)+\gamma\sum_{s'\in S}p(s'|s)V(s')
\end{aligned}
\]</div>
<p>​       The above formula is Bellman equation.</p>
<ul>
<li>Action-Value Function</li>
<li><span class="arithmatex">\(Q_\pi(s_t,a_t)=\mathbb{E}_{S_{t+1},A_{t+1},\cdots,S_n,A_n}\Big[U_t\Big|S_t=s_t,A_t=a_t\Big]\)</span></li>
<li>Regard <span class="arithmatex">\(S_{t+1},...S_n\)</span> and <span class="arithmatex">\(A_{t+1},...,A_n\)</span> as random variables. </li>
<li><span class="arithmatex">\(Q_\pi(s_t,a_t)\)</span> is dependent of <span class="arithmatex">\(S_{t+1},...S_n\)</span> and <span class="arithmatex">\(A_{t+1},...,A_n\)</span>.</li>
<li><a class="glightbox" href=".static/image-20231123220145161.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="image-20231123220145161" src=".static/image-20231123220145161.png" /></a></li>
<li>Evaluates how good it is for an agent to pick action <span class="arithmatex">\(a\)</span> while being in state <span class="arithmatex">\(s\)</span>.</li>
<li>Relawtion with State-Value Function.<ul>
<li>
<div class="arithmatex">\[Q_\pi(s,a)=r(s,a)+\gamma\sum_{s^{\prime}\in S}P(s^{\prime}|s,a)V^\pi(s^{\prime})\]</div>
</li>
</ul>
</li>
<li>
<p>Optimal action-value function</p>
</li>
<li>
<p><span class="arithmatex">\(Q^*(s_t,{a_t})=\underset{\pi}{\max}Q_\pi(s_t,a_t).\)</span></p>
</li>
<li>Whatever policy function <span class="arithmatex">\(π\)</span> is used, the result of taking <span class="arithmatex">\(a_t\)</span> at state <span class="arithmatex">\(s_t\)</span> cannot be better than <span class="arithmatex">\(Q^*(s_t,{a_t})\)</span>.</li>
<li>Exclude the influenced of strategy <span class="arithmatex">\(\pi\)</span>.</li>
<li><del>Input <span class="arithmatex">\(s_t\)</span>, output judgment for <span class="arithmatex">\(a_t\)</span> (vector), we can judge if <span class="arithmatex">\(a_t\)</span> is good at <span class="arithmatex">\(s_t\)</span> by <span class="arithmatex">\(Q^*(s_t,a_t)\)</span>.</del></li>
<li>
<p>State-Value Function</p>
</li>
<li>
<p><span class="arithmatex">\(V_\pi(s)=\mathbb{E}_\pi\big[U_t\mid S_t=s\big]\)</span></p>
</li>
<li>Consider $ A\sim\pi(\cdot|s_{t})$.</li>
<li>
<p>Relation with Action-Value Function.</p>
<ul>
<li><span class="arithmatex">\(V_{\pi}(s_{t})=\mathbb{E}_{A}\left[Q_{\pi}(s_{t},A)\right]=\underset{a}{\sum}\pi(a|s_{t})\cdot Q_{\pi}(s_{t},a)\)</span></li>
<li><span class="arithmatex">\(V_{\pi}(s_{t})=\mathbb{E}_{A}\left[Q_{\pi}(s_{t},A)\right]=\int\pi(a|s_{t})\cdot Q_{\pi}(s_{t},a)\text{d}a\)</span></li>
</ul>
</li>
<li>
<p>Evaluates how good the situation is in state <span class="arithmatex">\(s\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(\mathbb{E}_S[V_\pi(S)]\)</span> evaluates how good the policy <span class="arithmatex">\(\pi\)</span> is.</p>
</li>
<li>
<p>Markov decision process (MDP)</p>
</li>
<li>
<p><a href="https://hrl.boyuai.com/chapter/1/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B">Link</a></p>
</li>
<li>
<p>Deterministic and stochastic</p>
</li>
</ul>
<hr />
<p><a class="glightbox" href=".static/image-20231123221452360.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="image-20231123221452360" src=".static/image-20231123221452360.png" /></a></p>
<blockquote>
<p>So we have two choices, looking for good policy or optimal action-value function.</p>
</blockquote>
<hr />
<p>一局游戏：episode  reward <span class="arithmatex">\(R=\sum_{t=1}^Tr_t\)</span></p>
<p>How to do the optimization here is the main challenge in RL.
$$
\begin{aligned}
p_{\theta}(\tau)&amp; =p\left(s_1\right)p_\theta\left(a_1|s_1\right)p\left(s_2|(s_1,a_1)\right)p_\theta\left(a_2|s_2\right)p\left(s_3|(s_2,a_2)\right)\cdots   \
&amp;=p\left(s_1\right)\prod_{t=1}^Tp_\theta\left(a_t|s_t\right)p\left(s_{t+1}|(s_t,a_t)\right)
\end{aligned}
$$
<span class="arithmatex">\(R(τ)\)</span>并不只是一个标量（scalar），它是一个随机变量，因为actor在给定同样的状态下会采取什么样的动作是有随机性的  </p>
<p><span class="arithmatex">\(\bar{R}_\theta=\sum_\tau R(\tau)p_\theta(\tau)\)</span></p>
<p><a class="glightbox" href=".static/4.6.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="img" src=".static/4.6.png" /></a></p>
<p>计算期望奖励 <span class="arithmatex">\(\bar{R}_{\theta}\)</span> 的梯度时，只有后者 <span class="arithmatex">\(p_\theta\)</span> 与策略有关。
$$
\begin{aligned}
        \nabla \bar{R}<em _tau="\tau">{\theta}&amp;=\sum</em> R(\tau) \nabla p_{\theta}(\tau)\&amp;=\sum_{\tau} R(\tau) p_{\theta}(\tau) \frac{\nabla p_{\theta}(\tau)}{p_{\theta}(\tau)} \&amp;=
        \sum_{\tau} R(\tau) p_{\theta}(\tau) \nabla \log p_{\theta}(\tau) \
        &amp;=\mathbb{E}<em _theta="\theta">{\tau \sim p</em>(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right]
        \end{aligned} \tag{4.2}
$$
实际上期望值 <span class="arithmatex">\(\mathbb{E}_{\tau \sim p_{\theta}(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right]\)</span> 无法计算，所以我们用采样的方式采样 <span class="arithmatex">\(N\)</span> 个 <span class="arithmatex">\(\tau\)</span>并计算每一个的值，把每一个的值加起来，就可以得到梯度，即
$$
\begin{aligned}
        \mathbb{E}<em _theta="\theta">{\tau \sim p</em>(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right] &amp;\approx \frac{1}{N} \sum_{n=1}^{N} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(\tau^{n}\right) \
        &amp;=\frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(a_{t}^{n} \mid s_{t}^{n}\right)
        \end{aligned}
$$
<span class="arithmatex">\(\nabla \log p_{\theta}(\tau)\)</span> 的具体计算过程可写为
$$
    \begin{aligned}
        \nabla \log p_{\theta}(\tau) &amp;= \nabla \left(\log p(s_1)+\sum_{t=1}^{T}\log p_{\theta}(a_t|s_t)+ \sum_{t=1}^{T}\log p(s_{t+1}|s_t,a_t) \right) \
        &amp;= \nabla \log p(s_1)+ \nabla \sum_{t=1}^{T}\log p_{\theta}(a_t|s_t)+  \nabla \sum_{t=1}^{T}\log p(s_{t+1}|s_t,a_t) \
        &amp;=\nabla \sum_{t=1}^{T}\log p_{\theta}(a_t|s_t)\
        &amp;=\sum_{t=1}^{T} \nabla\log p_{\theta}(a_t|s_t)
        \end{aligned}
$$
注意， <span class="arithmatex">\(p(s_1)\)</span> 和 <span class="arithmatex">\(p(s_{t+1}|s_t,a_t)\)</span> 来自环境，<span class="arithmatex">\(p_\theta(a_t|s_t)\)</span> 来自智能体。<span class="arithmatex">\(p(s_1)\)</span> 和 <span class="arithmatex">\(p(s_{t+1}|s_t,a_t)\)</span> 由环境决定，与 <span class="arithmatex">\(\theta\)</span> 无关，因此 <span class="arithmatex">\(\nabla \log p(s_1)=0\)</span> ，<span class="arithmatex">\(\nabla \sum_{t=1}^{T}\log p(s_{t+1}|s_t,a_t)=0\)</span>。</p>
<div class="arithmatex">\[
\begin{aligned}
        \nabla \bar{R}_{\theta}&amp;=\sum_{\tau} R(\tau) \nabla p_{\theta}(\tau)\\&amp;=\sum_{\tau} R(\tau) p_{\theta}(\tau) \frac{\nabla p_{\theta}(\tau)}{p_{\theta}(\tau)} \\&amp;=
        \sum_{\tau} R(\tau) p_{\theta}(\tau) \nabla \log p_{\theta}(\tau) \\
        &amp;=\mathbb{E}_{\tau \sim p_{\theta}(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right]\\
        &amp;\approx \frac{1}{N} \sum_{n=1}^{N} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(\tau^{n}\right) \\
        &amp;=\frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}} R\left(\tau^{n}\right) \nabla \log p_{\theta}\left(a_{t}^{n} \mid s_{t}^{n}\right)
        \end{aligned} \tag{4.3}
\]</div>
<p>在我们采样到的数据里面，采样到在某一个状态 <span class="arithmatex">\(s_t\)</span> 要执行某一个动作 <span class="arithmatex">\(a_t\)</span>，<span class="arithmatex">\((s_t,a_t)\)</span> 是在整个轨迹 <span class="arithmatex">\(\tau\)</span> 的里面的某一个状态和动作的对。假设我们在 <span class="arithmatex">\(s_t\)</span> 执行 <span class="arithmatex">\(a_t\)</span>，最后发现 <span class="arithmatex">\(\tau\)</span> 的奖励是正的，我们就要增加在 <span class="arithmatex">\(s_t\)</span> 执行 <span class="arithmatex">\(a_t\)</span> 的概率。反之，如果在 <span class="arithmatex">\(s_t\)</span> 执行 <span class="arithmatex">\(a_t\)</span> 会导致 <span class="arithmatex">\(\tau\)</span> 的奖励变成负的， 我们就要减少在 <span class="arithmatex">\(s_t\)</span> 执行 <span class="arithmatex">\(a_t\)</span> 的概率。这怎么实现呢？我们用梯度上升来更新参数，原来有一个参数 <span class="arithmatex">\(\theta\)</span> ，把 <span class="arithmatex">\(\theta\)</span>  加上梯度<span class="arithmatex">\(\nabla \bar{R}_{\theta}\)</span>，当然我们要有一个学习率 <span class="arithmatex">\(\eta\)</span>，学习率也是要调整的，可用 Adam、RMSProp 等方法来调整学习率，即
$$
\theta \leftarrow \theta+\eta \nabla \bar{R}_{\theta}
$$</p>
<p>Critic</p>
<ul>
<li>Sparse Reward  If <span class="arithmatex">\(r_t\)</span> = 0 in most cases</li>
<li>
<p>Reward Shaping 定义一些新的小奖励</p>
</li>
<li>
<p>No Reward: Learning from Demonstration</p>
</li>
<li>Inverse Reinforcement Learning<h2 id="--using-the-reward-function-to-find-the-optimal-actor">- Using the reward function to find the optimal actor<a class="headerlink" href="#--using-the-reward-function-to-find-the-optimal-actor" title="Permanent link">&para;</a></h2>
</li>
</ul>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime">2024年2月4日 15:24:57</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime">2023年12月2日 14:56:35</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "content.code.annotate", "navigation.tracking", "navigation.indexes", "navigation.top", "navigation.path", "toc.follow", "navigation.footer", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.tooltips", "content.code.select"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
        
          <script src="../../assets/javascripts/mathjax.js"></script>
        
      
        
          <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        
      
        
          <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
        
          <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
        
      
        
          <script src="../../assets/javascripts/link.js"></script>
        
      
        
          <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>